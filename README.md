# Knowledge-Distillation
in this project we are going to create a research that implement the Knowledge Distillation methods on the nerual networks and comparing the efficiency of the methods of the Knowledge Distillaion between the students and the teachers models 

this github repositories will include all the code that is nessesary for building and preparing the data for the models and it will also include all the code that was used to build the Knowledge Distillaion method 
# The Final Code
in this project the final code is in the folder **Experiments of Knowledge Distillation ** only !!
in this folder we have two another folders ONLINE & OFFLINE which includes the experiments of the KD.
